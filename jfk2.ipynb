{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fdfc78-95f2-41ea-8933-6e1ccce6ca9a",
   "metadata": {},
   "source": [
    "## Creating An AI-Based JFK Speech Writer: Part 2\n",
    "-----------------------\n",
    "\n",
    "__[1. Introduction](#first-bullet)__\n",
    "\n",
    "__[2. Data Preparation](#second-bullet)__\n",
    "\n",
    "__[3. A Bidirectional GRU Model](#third-bullet)__\n",
    "\n",
    "__[4. Generating Text](#fourth-bullet)__\n",
    "\n",
    "__[5. Next Steps](#fifth-bullet)__\n",
    "\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "----\n",
    "\n",
    "In this blog post I follow up on the last [post](http://michael-harmon.com/blog/jfk1.html) and develop a model for text generation with [Recurrent Neural Networks](https://en.wikipedia.org/wiki/Recurrent_neural_network). I'll build a bi-directional [gated recurrent unit (GRU)](https://en.wikipedia.org/wiki/Gated_recurrent_unit) that is trained on speeches made by [President John F. Kennedy](https://en.wikipedia.org/wiki/John_F._Kennedy). Specifically, I'll go over a how to build a model that predicts the \"next word\" in a sentence based off of the words coming before it. This was challenging for me due to the data preparation needs of this problem. The data preparation was more involved then other posts that I have done on natural language processing since it involves modeling a sequences of words instead of a \"[bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model).\"\n",
    "\n",
    "The concept of sequence modeling in recurrent neural networks is different from other models that I have done in the past and I will spend some time covering this topic. Interestingly, the next word prediction turns out to be a multi-class classification problem, albeit with a very large number of classes! Let's dig into the problem. \n",
    "\n",
    "The first step is to import the necessary [TensorFlow](https://www.tensorflow.org/) and [Google Cloud](https://www.tensorflow.org/) packages (since the data is in [Google Cloud Storage](https://cloud.google.com/storage?)) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9501bfaf-82da-4796-9d43-2faeb403eafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity('ERROR')\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b761f9-0cc8-4488-a4fe-de221841d6cb",
   "metadata": {},
   "source": [
    "## Data Preparation <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06a580-c28a-4bb6-bac3-a2d4691a6eb8",
   "metadata": {},
   "source": [
    "I can connect to [Google Cloud Storage](https://cloud.google.com/storage?) to download the all the concatenated speeches by President Kennedy. The first thing I do is get my credentials and then instantiate the client to connect to the bucket `gs://harmon-kennedy/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdc91d6-7a75-417b-8b59-87896ef101b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')\n",
    "client = storage.Client(project=credentials.project_id, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "44272e52-23c0-44dc-90c5-16b0f4d0cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = client.get_bucket(\"harmon-kennedy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda80a0a-175e-4220-b31d-c116dafb78f9",
   "metadata": {},
   "source": [
    "And download all the speeches that concatenated into one file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817b0d05-e64f-43b7-ae43-8f285d6d867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(\"all_jfk_speeches.txt\")\n",
    "text = blob.download_as_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27642d-1e15-400c-9940-b7e668bd1dce",
   "metadata": {},
   "source": [
    "We can see the first 300 characters of the text are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "481cf8e1-2fdd-49b3-8761-3732fbf62420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of particular importance to South Dakota are the farm policies of the Republican party - the party of Benson, Nixon and Mundt - the party which offers our young people no incentive to return to the farm - which offers the farmer only the prospect of lower and lower income - and which offers the nati'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c4565-e508-49ad-a47b-05bb9ed3339f",
   "metadata": {},
   "source": [
    "For getting situated I can get the number of characters in the text as well as the number of unique characters,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457436ac-a059-490b-972e-07865c7778ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 7734579 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687e8070-acc6-46aa-ac52-078205307ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f25ab2-61a1-442b-a3c7-c273290c7bc4",
   "metadata": {},
   "source": [
    "Since I'll be making a word level model this isn't totally helpful. Instead I'll get the total number of words and number of unique words. To do this I need to clean the text, convert newline characters to space, remove non-English characters and convert everything to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5eff3cd0-0b23-48bc-8104-50fe96dc19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.replace(\"\\n\", \" \").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "55f8db83-9920-467d-bbab-dce5cddce87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = [word.lower()for word in words if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f2720385-5146-412d-b740-4bdba2bcdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb4259-a678-4a40-a31d-72ea4378122b",
   "metadata": {},
   "source": [
    "We can see the impact this had on the same text from above and get the total number of words and unique words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ebcbb8d3-4021-4e0e-837b-b1cbcaed9a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of particular importance to south dakota are the farm policies of the republican party the party of nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the nation the vision of'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "31e792fb-2273-42f5-ba13-7e5aff02e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196835 number of clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(clean_words)} number of clean words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f84fb4b9-c4a0-4e15-b984-f23593f009dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19291 unique clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(set(clean_words))} unique clean words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac90d471-6f4c-4b92-9e63-c2c179dd06a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7533442"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f1925-d47e-4388-a83d-d5cadd1aa9da",
   "metadata": {},
   "source": [
    "The way I will build a word level text generation model is to take a sequence of N words and then predict the next one. To create a training set, I break up the text into sliding widows where the feature vector **x** is the N words in the text and the target y is the N+1 word in the text. We repeat this N=1,2,3,4,... \n",
    "\n",
    "For instance take the sentence \"The man is walking down the street.\" If we want to build a model that predicts the next word based on the 4 before it we would have 4 training examples as shown below,\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/nextword.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://www.youtube.com/watch?v=VAMKuRAh2nc\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "For my model I'll use `seq_length` to be the number words to use in the text to predict the next word. In order to be able to predict the next word I need to reduce the total number words that are possible to predict. I'll limit the number of possible words to be of size `vocab_size`. That means this classification problem will be a `vocab-size`-class problem.\n",
    "\n",
    "In order to convert the text which is represented as a sequence of words into numerical vectors I'll use the [TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) class. I discuss this topic more in a prior post which you can read [here](http://michael-harmon.com/blog/NLP4.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c010404d-c093-49fa-a040-84eea850f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "seq_length = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6f28d-d856-4ac8-995d-4097ad956b32",
   "metadata": {},
   "source": [
    "We instantiate the TextVectorization layer and fit it to the text we have so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dd525c78-50fb-4edf-a80d-1d9bb0cfe9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    pad_to_max_tokens=True,\n",
    "    output_sequence_length=seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "74c5c2cb-31e0-492f-823d-5402f1e3c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 19:37:54.152222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer.adapt([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95d66a-9839-425f-9d6b-ece4d8ddbba9",
   "metadata": {},
   "source": [
    "I can then get the set of words in my \"vocabulary\" and create a dictionary to look up each word to its numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b0adfe7c-c9b4-4997-9d81-53332c08d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15fcda3-3b45-4a21-b8f7-4985f2cfb5b0",
   "metadata": {},
   "source": [
    "We can get the numerical value for each of the first two words in the example text above,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "97017125-2d21-4d13-ad8a-7ee54a9ed1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a9b20cd0-2586-448a-832d-0c50760769af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['particular']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288ab18-709b-4f59-9670-673bdd49f0af",
   "metadata": {},
   "source": [
    "Now we get the numerical value for the out of vocabulary token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b47c0035-4f44-48b4-8edb-7bc9b4f39114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['[UNK]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8192b-2747-4955-a65a-dadc41d71889",
   "metadata": {},
   "source": [
    "Next I'll create the dataset X and y, where X is the features are the sequence of words and y is the target which is the next word in that sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "41f01a9d-5f4b-4388-a29e-468ddb8e5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_seq = [clean_words[i:i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]\n",
    "next_word = [clean_words[i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e414148-051d-43da-a694-3b14466d08e1",
   "metadata": {},
   "source": [
    "Each entry in `words_seq` is a list of the `seq_length` words that make that sequence in that training example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "241e7f43-c684-4977-a802-ac741f827a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['of', 'particular', 'importance', 'to', 'south', 'dakota', 'are',\n",
       "        'the', 'farm', 'policies'], dtype='<U20'),\n",
       " array(['particular', 'importance', 'to', 'south', 'dakota', 'are', 'the',\n",
       "        'farm', 'policies', 'of'], dtype='<U20')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_seq[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f4cbe-27fb-4e33-b099-0f2bc8fa242a",
   "metadata": {},
   "source": [
    "I then convert those the list of lists into a list of strings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ebfb75b6-e61d-4575-b3a8-eee2c5623dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['of particular importance to south dakota are the farm policies',\n",
       "       'particular importance to south dakota are the farm policies of'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\" \".join(words_seq[i]) for i in range(len(next_word)) if next_cat[i] != 1])\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd76360-491d-4d1b-9623-d6a56a263722",
   "metadata": {},
   "source": [
    "Notice that I only do this where the target word is not out of the vocabulary word.\n",
    "\n",
    "The next two words that correspond to the targets for the examples above are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1f6d20cc-c310-416f-b868-71f78366c31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'the']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a3a51-08e8-4ee9-bac1-b303b408db9c",
   "metadata": {},
   "source": [
    "Now I'll convert the next word to a numerical value using the `word_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b121c151-2f0a-43c7-af72-4442aa2d4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_cat = np.array([word_index.get(word, 1) for word in next_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "817e9cb9-1b83-4b1a-87ee-c110d79d73b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cat[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bef3ba-cab0-457f-b585-6d2adeae3079",
   "metadata": {},
   "source": [
    "Now I need to one hot encode these variables and filter out those that correspond to the out of vocabulary tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0676294e-0c54-4686-ac32-5b08a4ca6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.keras.utils.to_categorical([cat for cat in next_cat if cat != 1])\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292b1a7-3150-4d37-b2b7-e06c3ae5b77b",
   "metadata": {},
   "source": [
    "We can see then see the size of each of the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c5d66dd7-4830-4e8a-9581-c8c4b6b304d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179990,)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f5fedb18-88b8-48bc-a1b3-2b0ef538a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179990, 10000)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c264a6-105d-4eff-8b1f-749c3be1bf1d",
   "metadata": {},
   "source": [
    "Now to see what effect the vectorizer layer has on the text I'll feed the first two sequences above through the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "abcb148f-7bd2-47dd-a30c-cd668f96e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=int64, numpy=\n",
       "array([[   3,  758,  692,    5,  430, 2268,   16,    2,  156,  280],\n",
       "       [ 758,  692,    5,  430, 2268,   16,    2,  156,  280,    3]])>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.call(X[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d4ce1-72c6-4d84-a9e3-73e592336708",
   "metadata": {},
   "source": [
    "The vectorizer layer converts the array of strings with shape `(1179990,)` to an matrix of integers of shape `(1179990, seq_length)`. Each entry in the array will be a integer from 1 to `vocab_size` and is the integer representation for each word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9371bd-fba2-4e1b-80d2-cbd559f98a7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A Bidirectional GRU Model  <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "------------\n",
    "[Recurrent Neural Networks (RNN)](https://en.wikipedia.org/wiki/Recurrent_neural_network) are used to model sequences. They use an internal state, h, to act as memory to process these sequences and \"remember\" things from the past. A quintessential diagram of a RNN is shown below, \n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/rnn.svg\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://en.wikipedia.org/wiki/Recurrent_neural_network#/media/File:Recurrent_neural_network_unfold.svg/\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "The RNN on the left is \"un-rolled\" to the right to show how it processes a sequence of inputs **x** into outputs **o**, there is a subscript *t* that denotes entry in the sequence. The subscript for each **h** is used to denote the value the internal state or memory cell in the t-th entry in the sequence.\n",
    "\n",
    "There are quite a few types of RNN's that are shown below,\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/types.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recurrent-neural-network/recurrent_neural_networks/\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "The model I am building where I use a sequence of words to predict the next word is a \"many-to-one\" model. Zooming into the the green blocks we focus on the specific type of RNN cell I use called a [Gated Recurrent Unit (GRU)](https://en.wikipedia.org/wiki/Gated_recurrent_unit). The details of a GRU cell are shown below.\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/gru.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/bidirectionalgru.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://www.researchgate.net/figure/The-structure-of-a-bidirectional-GRU-model_fig4_366204325\n",
    "</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd659caf-03e0-46e2-b93c-4d1a7900090b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8f7b61a-8021-400a-a988-9158e897b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dd297be0-eca7-4298-a899-b4c3509da016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JFKSpeechWriter(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 text: str, \n",
    "                 seq_length: int,\n",
    "                 vocab_size: int, \n",
    "                 embedding_dim: int, \n",
    "                 units: int) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vectorizer_layer = TextVectorization(\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    max_tokens=vocab_size,\n",
    "                                    output_mode=\"int\",\n",
    "                                    pad_to_max_tokens=True,\n",
    "                                    output_sequence_length=seq_length,\n",
    "                              )\n",
    "        self.embedding_layer =  tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.GRU_layer = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units))\n",
    "        self.dense_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "        \n",
    "        self.vectorizer_layer.adapt([text])\n",
    "        \n",
    "    def call(self, input_str: str) -> int:\n",
    "        # x = self.input_layer(input_str)\n",
    "        x = self.vectorizer_layer(input_str)\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.GRU_layer(x)\n",
    "        return self.dense_layer(x)\n",
    "        \n",
    "    def get_wordmap(self) -> Dict[int, str]:\n",
    "        voc = self.vectorizer_layer.get_vocabulary()\n",
    "        word_index = dict(zip(voc, range(len(voc))))\n",
    "        return dict(map(reversed, word_index.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e437ea74-66aa-4443-b9ba-0546c723d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:00:10.472779: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = JFKSpeechWriter(text=text, \n",
    "                        seq_length=20, \n",
    "                        vocab_size=10000, \n",
    "                        embedding_dim=128, \n",
    "                        units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "90115353-02c6-4a9b-ba91-5d3f58ee31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a75bc4-47ec-4fb6-9293-88f413a7f782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63d17714-af04-444e-8eb7-9093ceae9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f976cdd-2a28-487d-9590-908aee6cfd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:100000], y[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "109c3692-dfcc-4477-8049-99a421ae1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd91066d-360d-4965-b820-0ffb377b57a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'state laws in states such as massachusetts on the other hand union security provisions more liberal than tafthartley are not'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f0d5852d-b459-4076-8da3-972b6e4bc76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:00:17.790011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.016253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.025332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.136763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.151356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/625 [============================>.] - ETA: 0s - loss: 6.7281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:00:38.088691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:38.185708: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:38.195500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 24s 36ms/step - loss: 6.7286 - val_loss: 6.4995\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 6.3093 - val_loss: 6.4152\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 6.1363 - val_loss: 6.3013\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 20s 33ms/step - loss: 5.9251 - val_loss: 6.2154\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 5.7108 - val_loss: 6.1584\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 5.5084 - val_loss: 6.1019\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 5.3100 - val_loss: 6.0729\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 5.1067 - val_loss: 6.0613\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 4.9310 - val_loss: 6.0495\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 4.7657 - val_loss: 6.0480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dbdfd430>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f48f1138-1d0e-464c-af38-91abe75cbb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 07:42:02.923068: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x2dbebc400> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x2e4f8e8b0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"jfk_model\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e56b263f-563d-453b-8442-bc19585a0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"jfk_speech_writer_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_4 (TextV  multiple                 0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     multiple                  1280000   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  multiple                 74496     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  1290000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,644,496\n",
      "Trainable params: 2,644,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1185a6-16e6-4110-892f-768c77c0296e",
   "metadata": {},
   "source": [
    "## Generating Text  <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1c674c83-7731-470a-b6d3-ef5eebc76154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 07:42:58.035546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-07 07:42:58.040803: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"jfk_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "185f96ca-5f2b-4580-bc14-194cb2963bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = str(X[688394])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "626a08ad-a625-4c14-b148-ab071a2e6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and constitution and in the american public school system and he stated flatly that he recognized no power in the'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9385fdf7-eeb3-462c-ac0b-a6210ddb3b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:59:49.825963: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 17:59:49.895592: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 17:59:49.905844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4ca25393-54b9-46e6-832c-9a19a68d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = model.get_wordmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649441b5-ee54-47f7-bd60-19dcad6a3674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e4045a40-ed4a-43e9-bc4c-99e99bd4f687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'united'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map[np.argmax(y_pred[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceef283-b331-46c3-9ff3-0d8bec8b178f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "966ff16b-4dc2-465c-947a-5a7e0220b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_words(input_str, n):\n",
    "    final_str = ''\n",
    "    for i in range(n):\n",
    "        prediction = model.predict([input_str], verbose=0)\n",
    "        next_word = reverse_word_map[np.argmax(prediction[0])]\n",
    "        final_str += next_word + ' ' \n",
    "        input_str += ' ' + next_word\n",
    "        input_str = ' '.join(input_str.split(' ')[1:])\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d16adbda-a19d-4077-b874-f9bd3a882b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = next_words(test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ddebd14f-9b7a-47af-bc03-accd70231cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and constitution and in the american public school system and he stated flatly that he recognized no power in the words of the house of representatives and women of the '"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test + \" \" + new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ee53b-ebf4-4ba3-9f03-cc5dec98703d",
   "metadata": {},
   "source": [
    "## Next Steps  <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b83db6-16ba-45f3-a32a-53cc1c027674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e771b15-f506-4ab9-a94e-2e7ef907fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepgreen)",
   "language": "python",
   "name": "deepgreen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
