{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fdfc78-95f2-41ea-8933-6e1ccce6ca9a",
   "metadata": {},
   "source": [
    "## Creating An AI-Based JFK Speech Writer: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e378479-d924-4c8d-8523-4bd13cedbda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "tf.compat.v1.logging.set_verbosity('ERROR')\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdc91d6-7a75-417b-8b59-87896ef101b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "from google.cloud.exceptions import Conflict\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')\n",
    "\n",
    "client = storage.Client(project=credentials.project_id,\n",
    "                        credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44272e52-23c0-44dc-90c5-16b0f4d0cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = client.get_bucket(\"harmon-kennedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817b0d05-e64f-43b7-ae43-8f285d6d867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(\"all_jfk_speeches.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3583a63c-5814-4924-ba25-b48eb26f1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = blob.download_as_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cf8e1-2fdd-49b3-8761-3732fbf62420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457436ac-a059-490b-972e-07865c7778ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 7734579 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687e8070-acc6-46aa-ac52-078205307ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e5885c-c94f-4aab-9769-50c50c0c86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in_words = [w for w in text.split(' ') if w.strip() != '' or w == '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49721bdc-5d7e-42dd-93a9-645aaf1bf428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1338872 words\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text_in_words)} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "357ae73c-5c78-43f0-bb28-6a00a7156fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42240 unique words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(set(text_in_words))} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eff3cd0-0b23-48bc-8104-50fe96dc19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    " \n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f8db83-9920-467d-bbab-dce5cddce87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = np.array(clean_doc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2720385-5146-412d-b740-4bdba2bcdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78fcdd29-d1d3-45d1-94a7-3375d67563c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of particular importance to south dakota are the farm policies of the republican party the party of benson nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the nation the vi'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e792fb-2273-42f5-ba13-7e5aff02e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1322685 number of clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(clean_words)} number of clean words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84fb4b9-c4a0-4e15-b984-f23593f009dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22681 unique clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(set(clean_words))} unique clean words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7d561-f0fb-4db4-b09d-771c82c099be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac90d471-6f4c-4b92-9e63-c2c179dd06a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7533442"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd525c78-50fb-4edf-a80d-1d9bb0cfe9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 16:00:15.343286: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-05 16:00:15.343452: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vocab_size = 10000\n",
    "seq_length = 20\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    pad_to_max_tokens=True,\n",
    "    output_sequence_length=seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c5c2cb-31e0-492f-823d-5402f1e3c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 16:00:16.178013: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-04-05 16:00:16.215535: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer.adapt([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0adfe7c-c9b4-4997-9d81-53332c08d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97017125-2d21-4d13-ad8a-7ee54a9ed1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9b20cd0-2586-448a-832d-0c50760769af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['particular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41f01a9d-5f4b-4388-a29e-468ddb8e5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_seq = [clean_words[i:i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]\n",
    "next_word = [clean_words[i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50be1c2f-bf0e-4e22-8a9e-e03cc10c65b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322664"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b121c151-2f0a-43c7-af72-4442aa2d4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_cat = np.array([word_index.get(word, 1) for word in next_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f0568dd-6eb0-4b74-ba89-c66be7235feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1322664,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0676294e-0c54-4686-ac32-5b08a4ca6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for i in range(len(next_word)):\n",
    "    if next_cat[i]  != 1:\n",
    "        X.append(\" \".join(words_seq[i]))\n",
    "        y.append(next_cat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c20d5335-a3cb-4b00-9bc6-a3a382ccf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5d66dd7-4830-4e8a-9581-c8c4b6b304d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5fedb18-88b8-48bc-a1b3-2b0ef538a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299332, 10000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8edda367-14da-4faf-9418-2ce9d165576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299332,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "720692c8-7992-492e-a548-a434902a8726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of particular importance to south dakota are the farm policies of the republican party the party of benson nixon and'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abcb148f-7bd2-47dd-a30c-cd668f96e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
       "array([   3,  758,  692,    5,  430, 2268,   16,    2,  156,  280,    3,\n",
       "          2,  152,   68,    2,   68,    3,  756,  193,    4])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.call(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f039260-604e-4ff3-a3ea-dbb9a4cd802d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mundt', 'the']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4713e693-f6fe-4b92-930e-1e8d2c987936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7294ad86-9e48-4bbb-b111-dddbf8f2d60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['nation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7ef562b-372b-4173-a3f3-d68f1ef25d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['[UNK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8b914f2-6a59-4ef0-b7b2-669c3c947a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd0151ef-f6b7-4364-b500-64f6f8117b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ab4aa87-9121-4572-8276-042b223d3f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299332, 10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7113ddab-04d9-4813-a009-d01b023343e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299332,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d455dea6-fcca-48d7-a3a1-9825c969057a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64fc0c77-c7d9-4f02-bc32-1b57f2ba0ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299332, 10000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9371bd-fba2-4e1b-80d2-cbd559f98a7e",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/44273249/in-keras-what-exactly-am-i-configuring-when-i-create-a-stateful-lstm-layer-wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8f7b61a-8021-400a-a988-9158e897b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "                tf.keras.Input(shape=(1,), \n",
    "                               dtype=tf.string, \n",
    "                               name='text'),\n",
    "                vectorize_layer,\n",
    "                tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "                tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
    "                tf.keras.layers.Dense(y.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90115353-02c6-4a9b-ba91-5d3f58ee31e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 20)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              74496     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10000)             1290000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,644,496\n",
      "Trainable params: 2,644,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63d17714-af04-444e-8eb7-9093ceae9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f976cdd-2a28-487d-9590-908aee6cfd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:100000], y[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "109c3692-dfcc-4477-8049-99a421ae1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd91066d-360d-4965-b820-0ffb377b57a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this growing deterioration of our natural resources despite the pressures of population growth we have in the past several years'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0d5852d-b459-4076-8da3-972b6e4bc76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 16:01:06.642846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:01:06.854292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:01:06.863950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:01:07.038112: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:01:07.051988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/625 [============================>.] - ETA: 0s - loss: 6.7328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 16:01:24.646652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:01:24.715426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:01:24.722140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 21s 31ms/step - loss: 6.7324 - val_loss: 6.4874\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 6.2851 - val_loss: 6.3469\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 6.0749 - val_loss: 6.2379\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 5.8688 - val_loss: 6.1784\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 5.6821 - val_loss: 6.1432\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 5.4954 - val_loss: 6.1046\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 5.3119 - val_loss: 6.0778\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 5.1260 - val_loss: 6.0484\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 4.9543 - val_loss: 6.0451\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 4.7884 - val_loss: 6.0618\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 4.6483 - val_loss: 6.0697\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 4.5165 - val_loss: 6.0855\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 4.4017 - val_loss: 6.1024\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 4.2912 - val_loss: 6.1258\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 4.1987 - val_loss: 6.1565\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 4.1024 - val_loss: 6.1677\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 4.0188 - val_loss: 6.1850\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 3.9429 - val_loss: 6.2028\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 3.8730 - val_loss: 6.2256\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 3.8143 - val_loss: 6.2487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d79b94c0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs =20, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "185f96ca-5f2b-4580-bc14-194cb2963bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = str(X[100020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a08ad-a625-4c14-b148-ab071a2e6435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9385fdf7-eeb3-462c-ac0b-a6210ddb3b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 16:08:04.225998: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:08:04.290177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 16:08:04.297113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "649441b5-ee54-47f7-bd60-19dcad6a3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4045a40-ed4a-43e9-bc4c-99e99bd4f687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map[np.argmax(y_pred[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceef283-b331-46c3-9ff3-0d8bec8b178f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99356d14-998c-4530-8db5-cec1a09865f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "966ff16b-4dc2-465c-947a-5a7e0220b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_tokens(input_str, n):\n",
    "    print (\"Seed -\",  input_str, sep = '\\n\\n')\n",
    "    final_string = ''\n",
    "    for i in range(n):\n",
    "        prediction = model.predict([input_str], verbose=0)\n",
    "        final_string = final_string + reverse_word_map[np.argmax(prediction[0])] + ' ' \n",
    "        input_str = input_str + ' ' + reverse_word_map[np.argmax(prediction[0])]\n",
    "        input_str = ' '.join(input_str.split(' ')[1:])\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d16adbda-a19d-4077-b874-f9bd3a882b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed -\n",
      "\n",
      "indifference where franklin roosevelt opened new horizons this administration sets ceilings where roosevelt urged a spirit of selfsacrifice we are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'going to rebuild the disabled '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_tokens(test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aba2c76e-9c5c-4315-be11-3b077441db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed -\n",
      "\n",
      "ask not what your country can do for you ask\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the and which '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_tokens(\"ask not what your country can do for you ask\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ee53b-ebf4-4ba3-9f03-cc5dec98703d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e771b15-f506-4ab9-a94e-2e7ef907fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepgreen)",
   "language": "python",
   "name": "deepgreen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
