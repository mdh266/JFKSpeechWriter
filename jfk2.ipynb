{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fdfc78-95f2-41ea-8933-6e1ccce6ca9a",
   "metadata": {},
   "source": [
    "## Creating An AI-Based JFK Speech Writer: Part 2\n",
    "-----------------------\n",
    "\n",
    "__[1. Introduction](#first-bullet)__\n",
    "\n",
    "__[2. Data Preparation](#second-bullet)__\n",
    "\n",
    "__[3. A Bidirectional GRU Model](#third-bullet)__\n",
    "\n",
    "__[4. Generating Text](#fourth-bullet)__\n",
    "\n",
    "__[5. Next Steps](#fifth-bullet)__\n",
    "\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "----\n",
    "\n",
    "In this blog post I follow up on the last [post](http://michael-harmon.com/blog/jfk1.html) and develop a model for text generation using [Recurrent Neural Networks](https://en.wikipedia.org/wiki/Recurrent_neural_network). I'll build a bi-directional [gated recurrent unit (GRU)](https://en.wikipedia.org/wiki/Gated_recurrent_unit) that is trained on speeches made by [President John F. Kennedy](https://en.wikipedia.org/wiki/John_F._Kennedy). Specifically, I'll go over how to build a model that predicts the \"next word\" in a sentence based off a sequence of the words coming before it. This project was more challenging than I initially anticipated due to the data preparation needs of the problem. The data preparation was more involved then other posts that I have done on natural language processing since it involves modeling a sequences of words instead of using a \"[bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model).\" I'll go over some of these details more in the post.\n",
    " \n",
    "The concept of sequence modeling in recurrent neural networks is also different from other models that I have done in the past and I will spend some time covering this topic. Interestingly, the next word prediction turns out to be a multi-class classification problem, albeit with a very large number of classes! Let's get started with the problem. \n",
    "\n",
    "The first step is to import the necessary [TensorFlow](https://www.tensorflow.org/) and [Google Cloud](https://www.tensorflow.org/) Python packages (since the data is in [Google Cloud Storage](https://cloud.google.com/storage?)) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9501bfaf-82da-4796-9d43-2faeb403eafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity('ERROR')\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b761f9-0cc8-4488-a4fe-de221841d6cb",
   "metadata": {},
   "source": [
    "## Data Preparation <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06a580-c28a-4bb6-bac3-a2d4691a6eb8",
   "metadata": {},
   "source": [
    "I next connect to [Google Cloud Storage](https://cloud.google.com/storage?) to download all the concatenated speeches by President Kennedy. To do this I get my GCP credentials and then instantiate the client to connect to the bucket `gs://harmon-kennedy/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdc91d6-7a75-417b-8b59-87896ef101b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')\n",
    "client = storage.Client(project=credentials.project_id, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44272e52-23c0-44dc-90c5-16b0f4d0cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = client.get_bucket(\"harmon-kennedy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda80a0a-175e-4220-b31d-c116dafb78f9",
   "metadata": {},
   "source": [
    "Now I can download all the speeches that were concatenated into one file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817b0d05-e64f-43b7-ae43-8f285d6d867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(\"all_jfk_speeches.txt\")\n",
    "text = blob.download_as_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27642d-1e15-400c-9940-b7e668bd1dce",
   "metadata": {},
   "source": [
    "I can see the first 300 characters of the text are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481cf8e1-2fdd-49b3-8761-3732fbf62420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of particular importance to South Dakota are the farm policies of the Republican party - the party of Benson, Nixon and Mundt - the party which offers our young people no incentive to return to the farm - which offers the farmer only the prospect of lower and lower income - and which offers the nati'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c4565-e508-49ad-a47b-05bb9ed3339f",
   "metadata": {},
   "source": [
    "To get situated with the data I can get the number of characters in the text as well as the number of unique characters,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457436ac-a059-490b-972e-07865c7778ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 7734579 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687e8070-acc6-46aa-ac52-078205307ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f25ab2-61a1-442b-a3c7-c273290c7bc4",
   "metadata": {},
   "source": [
    "Since I'll be making a word level model this isn't totally helpful. Instead I'll get the total number of words and number of unique words. To do this I need to clean the text; convert newline characters to spaces, remove non-English characters and convert characters to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eff3cd0-0b23-48bc-8104-50fe96dc19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.replace(\"\\n\", \" \").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55f8db83-9920-467d-bbab-dce5cddce87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = [word.lower() for word in words if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2720385-5146-412d-b740-4bdba2bcdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb4259-a678-4a40-a31d-72ea4378122b",
   "metadata": {},
   "source": [
    "The impact this had on the same text from above can be seen below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebcbb8d3-4021-4e0e-837b-b1cbcaed9a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of particular importance to south dakota are the farm policies of the republican party the party of nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the nation the vision of'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c958cf-2857-44f2-85c5-1debb08cb07e",
   "metadata": {},
   "source": [
    "The total number of clean words and unique clean words in the text are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e792fb-2273-42f5-ba13-7e5aff02e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196835 number of clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(clean_words)} number of clean words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84fb4b9-c4a0-4e15-b984-f23593f009dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19291 unique clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(set(clean_words))} unique clean words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f1925-d47e-4388-a83d-d5cadd1aa9da",
   "metadata": {},
   "source": [
    "Now let's talk about how we can process out text data for training a model to predict the next word.\n",
    "\n",
    "The way a word level text generation model is built is to take a sequence of N words and then predict the next one. To create a training set, the text is split up into sliding widows where the feature vector **x** is the N words in the sequence of text and the target y is the N+1 word in that text. We repeat this process for N=1,2,3,4,... \n",
    "\n",
    "For instance take the sentence \"the man is walking down the street.\" To build a model that predicts the next word based on the 4 word that come before it, it is necessary to create the 4 training examples as shown below,\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/nextword.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://www.youtube.com/watch?v=VAMKuRAh2nc\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "For this model I will use `seq_length` as `N` or the number words in the text used to predict the next word. In order to be able to predict the next word I need to reduce the total number words that are possible to predict to a finite number. This means limiting the number of possible words to be a set of size `vocab_size`. This in turn converts the next word prediction problem into a classification problem with `vocab-size` classes.\n",
    "\n",
    "In order to convert the text which is represented as a sequence of words into numerical vectors I'll use the [TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) class. This technique is discussed in more in a prior post which you can read [here](http://michael-harmon.com/blog/NLP4.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c010404d-c093-49fa-a040-84eea850f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15000\n",
    "seq_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6f28d-d856-4ac8-995d-4097ad956b32",
   "metadata": {},
   "source": [
    "I first instantiate the `TextVectorization` layer and fit it to the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd525c78-50fb-4edf-a80d-1d9bb0cfe9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 19:08:57.300905: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-01 19:08:57.301354: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer_layer = TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74c5c2cb-31e0-492f-823d-5402f1e3c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 19:08:58.454915: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-01 19:08:58.502828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "vectorizer_layer.adapt([clean_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95d66a-9839-425f-9d6b-ece4d8ddbba9",
   "metadata": {},
   "source": [
    "Note that I do this on the `clean_text` string and not the text string. \n",
    "\n",
    "I can then get the set of words in the `vectorizer_layer`'s \"vocabulary\" and create a dictionary to look up each word's equivalent numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0adfe7c-c9b4-4997-9d81-53332c08d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca6b53-efef-4d59-8943-f873facaa25f",
   "metadata": {},
   "source": [
    "We can see the vocab size of the `vectorizer_layer`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2b19e4b-b4ac-4d7e-ad04-0e5eae6d2bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15fcda3-3b45-4a21-b8f7-4985f2cfb5b0",
   "metadata": {},
   "source": [
    "The numerical value for each of the first two words in the example text above is then,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97017125-2d21-4d13-ad8a-7ee54a9ed1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b20cd0-2586-448a-832d-0c50760769af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['particular']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288ab18-709b-4f59-9670-673bdd49f0af",
   "metadata": {},
   "source": [
    "The numerical value for the \"out of vocabulary\" token is,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b47c0035-4f44-48b4-8edb-7bc9b4f39114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['[UNK]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8192b-2747-4955-a65a-dadc41d71889",
   "metadata": {},
   "source": [
    "Next I'll create the dataset X and y, where X is the vector of features, which in turn are numerical values for the sequence of words. The vector y is the target which is integer that represents the numerical value of next word in that sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f01a9d-5f4b-4388-a29e-468ddb8e5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_seq = [clean_words[i:i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]\n",
    "next_word = [clean_words[i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e414148-051d-43da-a694-3b14466d08e1",
   "metadata": {},
   "source": [
    "Each entry in `words_seq` is a list of the `seq_length` words or tokens that make that sequence in that training example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "241e7f43-c684-4977-a802-ac741f827a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of particular importance to south dakota are the farm policies of the republican party the party of nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the\n",
      "\n",
      "particular importance to south dakota are the farm policies of the republican party the party of nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the nation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for words in words_seq[:2]:\n",
    "    print(\" \".join(words) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145904f0-1aa6-4f44-9678-eb4c77366484",
   "metadata": {},
   "source": [
    "Now I'll convert the target vector of \"next words\" to a vector with \"numerical values\" using the `word_index` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4ab62a8-e925-472b-a55d-11cbe8f8a4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111,   2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cat = np.array([word_index.get(word, 1) for word in next_word])\n",
    "next_cat[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f4cbe-27fb-4e33-b099-0f2bc8fa242a",
   "metadata": {},
   "source": [
    "Notice that if the word is not in the `word_index` then it is given the out of vocabulary int of 1.\n",
    "\n",
    "Then I convert those list of lists into a list of strings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebfb75b6-e61d-4575-b3a8-eee2c5623dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['of particular importance to south dakota are the farm policies of the republican party the party of nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the'],\n",
       "       ['particular importance to south dakota are the farm policies of the republican party the party of nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the nation']],\n",
       "      dtype='<U406')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\" \".join(words_seq[i]) for i in range(len(next_word))\n",
    "              if next_cat[i] != 1]).reshape(-1,1)\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd76360-491d-4d1b-9623-d6a56a263722",
   "metadata": {},
   "source": [
    "The reason for doing this is that this way my model will be able to take inputs that are just plain text instead of needing lists of strings that represent that text. The later would require that new inputs to the model be pre-processed before being feed into the trained model, while the latter means a trained model can just take raw text as the input.\n",
    "\n",
    "\n",
    "Notice that I only included sequences of the text where the target word was not an out of vocabulary word. \n",
    "\n",
    "The next two words that correspond to the targets for the examples above are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1f6d20cc-c310-416f-b868-71f78366c31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from', 'this']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bef3ba-cab0-457f-b585-6d2adeae3079",
   "metadata": {},
   "source": [
    "Lastly, I'll create the target vector by filtering out the case where value would be out-of-vocabulary tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0676294e-0c54-4686-ac32-5b08a4ca6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111,   2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([cat for cat in next_cat if cat != 1])\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239a666-35f7-4faa-9e33-130392cdc905",
   "metadata": {},
   "source": [
    "The reason for filtering the out-of-vocabulary tokens is I don't want to train a model that predicts out-of-vocabulary words since this would be meaningless to end users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292b1a7-3150-4d37-b2b7-e06c3ae5b77b",
   "metadata": {},
   "source": [
    "The size of each of the feature dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5d66dd7-4830-4e8a-9581-c8c4b6b304d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192491, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d117162f-00be-4f79-a67e-2861c3d8fe7e",
   "metadata": {},
   "source": [
    "That is X is technically a 1-D array, but each entry in X is an array that contains the text. Once we transform the X array we will have a matrix it will be of size,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5194d94-86b2-49f6-8798-cbae25641e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1192491, 50])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_layer.call(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9658028-cc49-45db-80ec-c97f137ab687",
   "metadata": {},
   "source": [
    "This is what we would expect, 50 features per entry in our design matrix. Again, I use this set up where X is a 1 dimensional array so that my model has only input of text.\n",
    "\n",
    "The target variable has shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5fedb18-88b8-48bc-a1b3-2b0ef538a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192491,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c264a6-105d-4eff-8b1f-749c3be1bf1d",
   "metadata": {},
   "source": [
    "Now to see what effect the vectorizer layer has on the text I'll feed the first two sequences above through the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abcb148f-7bd2-47dd-a30c-cd668f96e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[   3,  717,  652,    5,  482, 2772,   16,    2,  143,  280,    3,\n",
       "           2,  142,   81,    2,   81,    3,  192,    4, 8230,    2,   81,\n",
       "          23, 1290,   13,  406,   57,   46, 3001,    5,  978,    5,    2,\n",
       "         143,   23, 1290,    2,  431,   60,    2, 2429,    3,  913,    4,\n",
       "         913,  285,    4,   23, 1290,    2],\n",
       "       [ 717,  652,    5,  482, 2772,   16,    2,  143,  280,    3,    2,\n",
       "         142,   81,    2,   81,    3,  192,    4, 8230,    2,   81,   23,\n",
       "        1290,   13,  406,   57,   46, 3001,    5,  978,    5,    2,  143,\n",
       "          23, 1290,    2,  431,   60,    2, 2429,    3,  913,    4,  913,\n",
       "         285,    4,   23, 1290,    2,  111]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_layer.call(X[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d4ce1-72c6-4d84-a9e3-73e592336708",
   "metadata": {},
   "source": [
    "The vectorizer layer converts the array of strings with shape `(1179990,)` to an matrix of integers of shape `(1179990, seq_length)`. Each entry in the array will be a integer from 1 to `vocab_size` and is the integer representation for each word.\n",
    "\n",
    "Now that we an understanding of how we can create the dataset let's talk about Recurrent Neural Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d42b72-0d91-4c25-83b3-c80362f00106",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A Bidirectional GRU Model  <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "------------\n",
    "[Recurrent Neural Networks (RNN)](https://en.wikipedia.org/wiki/Recurrent_neural_network) are deep learning models used to predict sequences. These models use an internal state, **h**, to act as memory that processes these sequences and \"remember\" things from the past. A quintessential diagram of a RNN is shown below, \n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/rnn.svg\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://en.wikipedia.org/wiki/Recurrent_neural_network#/media/File:Recurrent_neural_network_unfold.svg/\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "A RNN cell is shown on the left and on the right is the \"un-rolled\" version that shows how the cell processes a sequence of inputs **x** into outputs **o**; there is a subscript *t* that denotes entry in the sequence. The subscript for each **h** is used to denote the value the internal state or memory cell in the t-th entry in the sequence.\n",
    "\n",
    "There are a number of RNN's and a few are shown below,\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/types.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recurrent-neural-network/recurrent_neural_networks/\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "The model I am building in this post that uses a sequence of words to predict the next word is a \"many-to-one\" model. The many-to-one RNN gets its name since we using a sequence \"many\" of word to predict one word, i.e. the next word.  Zooming into the RNN cell we focus on a specific type of RNN called a [Gated Recurrent Unit (GRU)](https://en.wikipedia.org/wiki/Gated_recurrent_unit). The details of a GRU cell are shown below.\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/gru.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24198e23-b7a4-42aa-ae48-465f5e928b17",
   "metadata": {
    "tags": []
   },
   "source": [
    "There is a hidden state **h** that takes on values for each iteration *t*. There is a candidate update to the hidden state **h** with a ~ over it. The candidate update to the hidden state has values between -1 and +1 and is a function of the relevance gate **r** as well as the prior value of the hidden state and the current value of the input. The relevance gate is value between 0 and 1 and is a function of the prior value of the hidden state and the current value of the input. It controls the amount off effect that the prior hidden state value has on the candidate update value for the hidden state. \n",
    "\n",
    "Lastly, there is a forget gate **z** which is between 0 and 1 is a function of the prior value of the hidden state and the current value of the input. The forget gate is used to control whether we update the hidden state value or not. If `z = 1` then we update the internal state to be the candidate state. If `z = 0`, the value for the hidden state remains unchanged.\n",
    "\n",
    "Notice the hidden state value **h** of one iteration can be fed directly into the RNN as well as the input **x**. These variables are not necessarily scalars and are often vectors. \n",
    "\n",
    "In the model I am building the variables will be vectors of dimension `seq_length`. The output of the RNN cell is a vector of size `vocab_size`. To convert the hidden state vector **x** to **y** we apply a softmax function.\n",
    "\n",
    "Many times in natural language processing models make use of a [bi-directional RNN](https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks). In this type of model two RNN cells are used, one processing the sequence in the forward direction and one processing the sequence in the reverse direction. The architecture is shown below:\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/bidirectionalgru.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://www.researchgate.net/figure/The-structure-of-a-bidirectional-GRU-model_fig4_366204325\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba8d86-0b58-4ed1-b684-189bc6a3591c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice that the forward and backward GRU cells are both a function of the same input value **x** (both at the same time *t*), but are functions of different iterations hidden states **h** (different values of *t*. Both cells at the same iteration are used to compute the output at the same iteration. Bidirectional RNN's were introduced to increase the amount of input information available to the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1277db-8120-4a6d-9aab-f7225341fe3f",
   "metadata": {},
   "source": [
    "I create a bi-directional GRU model using [TensorFlow's subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models) methods below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7b61a-8021-400a-a988-9158e897b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class JFKSpeechWriter(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 text: str, \n",
    "                 seq_length: int,\n",
    "                 vocab_size: int, \n",
    "                 embedding_dim: int, \n",
    "                 units: int) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vectorizer_layer = TextVectorization(\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    max_tokens=vocab_size,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=seq_length,\n",
    "                              )\n",
    "        self.embedding_layer =  tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.GRU_layer = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units))\n",
    "        self.dense_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "        \n",
    "        self.vectorizer_layer.adapt([text])\n",
    "        \n",
    "    def call(self, input_str: str) -> int:\n",
    "        # x = self.input_layer(input_str)\n",
    "        x = self.vectorizer_layer(input_str)\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.GRU_layer(x)\n",
    "        return self.dense_layer(x)\n",
    "        \n",
    "    def get_wordmap(self) -> Dict[int, str]:\n",
    "        voc = self.vectorizer_layer.get_vocabulary()\n",
    "        word_index = dict(zip(voc, range(len(voc))))\n",
    "        return dict(map(reversed, word_index.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "787b1812-d474-4a6a-b3bf-b08cbb003a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 22:06:00.820847: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d00992d9-a390-4666-9b39-e46f2de6031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "             text: str, \n",
    "             seq_length: int,\n",
    "             vocab_size: int, \n",
    "             embedding_dim: int, \n",
    "             units: int\n",
    ") -> tf.keras.models.Sequential:\n",
    "    \n",
    "    vectorizer_layer = TextVectorization(\n",
    "                            standardize=\"lower_and_strip_punctuation\",\n",
    "                            max_tokens=vocab_size,\n",
    "                            output_mode=\"int\",\n",
    "                            output_sequence_length=seq_length)\n",
    "    \n",
    "    vectorizer_layer.adapt([text])\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "                    tf.keras.Input(shape=(1,), \n",
    "                                   dtype=tf.string, \n",
    "                                   name='text'),\n",
    "                    vectorizer_layer,\n",
    "                    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "                    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units)),\n",
    "                    tf.keras.layers.Dense(vocab_size, activation='softmax')])\n",
    "    \n",
    "    return vectorizer_layer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d31d03-5ce9-4d8b-8d7d-6627bc284492",
   "metadata": {},
   "source": [
    "The subclassing method in TensorFlow is used for novel techniques mainly for research problems. The model I am building is pretty standard, but I wanted to use this opportunity play around with the subclassing methodology.\n",
    "\n",
    "In the constructor each layer of the model is declared as an attribute of the object and the vectorizer layer is instantiated. The `call` method of the class is used to define the forward form of the model. Like in all Keras models, the forward form is all that is needed to be defined and Keras/Tensorflow handles computing the necessary information needed for [backpropegation](https://en.wikipedia.org/wiki/Backpropagation). The model consists of a vectorizer layer which converts the text which is made up of `seq_length` words into a `seq_length`-dimensional vector of integers that taken values between 1 and `vocab_size`. Next an embedding layer is applied, followed by a bi-directional GRU layer and softmax as the last layer to predict which of the `vocab_size` class the next word is.\n",
    "\n",
    "The last method of the class is `get_wordmap`. This function returns the reverse dictionary that converts a integer representation of words back to its English version. This function is used for converting the output of the model back an English word.\n",
    "\n",
    "Now, the model can be instantiated with 128 dimensional embedding layer and 64 unit GRU layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e437ea74-66aa-4443-b9ba-0546c723d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 17:27:08.047751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "vectorizer, model = build_model(text=text, \n",
    "                                seq_length=10, \n",
    "                                vocab_size=15000, \n",
    "                                embedding_dim=128, \n",
    "                                units=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12460e-0627-4989-85c4-2093013e4c52",
   "metadata": {},
   "source": [
    "Notice that for the vectorizer layer I have to pass the original text, `seq_length` and the `vocab_size` values to initialize that layer properly. \n",
    "\n",
    "Now we can compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90115353-02c6-4a9b-ba91-5d3f58ee31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdc123-9532-4574-8ee0-b50664711ffa",
   "metadata": {},
   "source": [
    "Normally in a Tensorflow model using a [Sequential model](https://www.tensorflow.org/guide/keras/sequential_model) or the [Functional API](https://www.tensorflow.org/guide/keras/functional) once the model is compiled the [summary](https://keras.io/api/models/model/#summary-method) method can be used to return information on the model. However, compiling the model is not sufficient for using the [summary](https://keras.io/api/models/model/#summary-method) method in the subclassing API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "577d4e4b-278f-4c3d-b8f0-fc03f4ed6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (tf.data.Dataset\n",
    "             .from_tensor_slices((X, y))\n",
    "             .shuffle(100000)\n",
    "             .batch(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3aab3120-fcae-4ee3-9644-b6aa54124130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "9301/9301 [==============================] - 259s 28ms/step - loss: 4.5997\n",
      "Epoch 2/25\n",
      "9301/9301 [==============================] - 252s 27ms/step - loss: 4.5852\n",
      "Epoch 3/25\n",
      "9301/9301 [==============================] - 441s 47ms/step - loss: 4.5704\n",
      "Epoch 4/25\n",
      "9301/9301 [==============================] - 259s 28ms/step - loss: 4.5621\n",
      "Epoch 5/25\n",
      "9301/9301 [==============================] - 254s 27ms/step - loss: 4.5535\n",
      "Epoch 6/25\n",
      "9301/9301 [==============================] - 631s 68ms/step - loss: 4.5507\n",
      "Epoch 7/25\n",
      "9301/9301 [==============================] - 975s 105ms/step - loss: 4.5423\n",
      "Epoch 8/25\n",
      "9301/9301 [==============================] - 940s 101ms/step - loss: 4.5410\n",
      "Epoch 9/25\n",
      "9301/9301 [==============================] - 887s 95ms/step - loss: 4.5354\n",
      "Epoch 10/25\n",
      "9301/9301 [==============================] - 1551s 167ms/step - loss: 4.5295\n",
      "Epoch 11/25\n",
      "9301/9301 [==============================] - 247s 27ms/step - loss: 4.5348\n",
      "Epoch 12/25\n",
      "9301/9301 [==============================] - 246s 26ms/step - loss: 4.5266\n",
      "Epoch 13/25\n",
      "9301/9301 [==============================] - 247s 27ms/step - loss: 4.5288\n",
      "Epoch 14/25\n",
      "9301/9301 [==============================] - 247s 26ms/step - loss: 4.5462\n",
      "Epoch 15/25\n",
      "9301/9301 [==============================] - 250s 27ms/step - loss: 4.5551\n",
      "Epoch 16/25\n",
      "9301/9301 [==============================] - 249s 27ms/step - loss: 4.5564\n",
      "Epoch 17/25\n",
      "9301/9301 [==============================] - 249s 27ms/step - loss: 4.5568\n",
      "Epoch 18/25\n",
      "9301/9301 [==============================] - 250s 27ms/step - loss: 4.5428\n",
      "Epoch 19/25\n",
      "9301/9301 [==============================] - 248s 27ms/step - loss: 4.5319\n",
      "Epoch 20/25\n",
      "9301/9301 [==============================] - 249s 27ms/step - loss: 4.5339\n",
      "Epoch 21/25\n",
      "9301/9301 [==============================] - 251s 27ms/step - loss: 4.5331\n",
      "Epoch 22/25\n",
      "9301/9301 [==============================] - 256s 27ms/step - loss: 4.5336\n",
      "Epoch 23/25\n",
      "9301/9301 [==============================] - 254s 27ms/step - loss: 4.5383\n",
      "Epoch 24/25\n",
      "9301/9301 [==============================] - 251s 27ms/step - loss: 4.5482\n",
      "Epoch 25/25\n",
      "9301/9301 [==============================] - 647s 70ms/step - loss: 4.5512\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2b86eabe-0593-48ae-af77-2680a5b44019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.7009258e-12, 9.8117747e-12, 4.6239831e-02, ..., 5.1395332e-09,\n",
       "        1.2419777e-08, 9.6487384e-12]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd91066d-360d-4965-b820-0ffb377b57a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['of particular importance to south dakota are the farm policies'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f0d5852d-b459-4076-8da3-972b6e4bc76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f48f1138-1d0e-464c-af38-91abe75cbb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x2cca13070> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x2cca3d460> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"jfk_model\")#, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e56b263f-563d-453b-8442-bc19585a0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, 10)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 10, 128)           1920000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15000)             1935000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,929,496\n",
      "Trainable params: 3,929,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1185a6-16e6-4110-892f-768c77c0296e",
   "metadata": {},
   "source": [
    "## Generating Text  <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c674c83-7731-470a-b6d3-ef5eebc76154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 21:36:37.025776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-22 21:36:37.030131: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"jfk_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ca25393-54b9-46e6-832c-9a19a68d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "reverse_word_map = dict(map(reversed, word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "649441b5-ee54-47f7-bd60-19dcad6a3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e4045a40-ed4a-43e9-bc4c-99e99bd4f687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(reverse_word_map[np.argmax(y_pred[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fceef283-b331-46c3-9ff3-0d8bec8b178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X[9342][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e878759b-d9e1-4d30-9ae6-c13d6bf8460f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food is increased and diversified agricultural production is essential both'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "966ff16b-4dc2-465c-947a-5a7e0220b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_words(input_str, n):\n",
    "    final_str = ''\n",
    "    for i in range(n):\n",
    "        prediction = model.predict(np.array([input_str]), verbose=0)\n",
    "        next_word = str(reverse_word_map[np.argmax(prediction[0])])\n",
    "        final_str += next_word + ' ' \n",
    "        input_str += ' ' + next_word\n",
    "        input_str = ' '.join(input_str.split(' ')[1:])\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d16adbda-a19d-4077-b874-f9bd3a882b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = next_words(test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ddebd14f-9b7a-47af-bc03-accd70231cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food is increased and diversified agricultural production is essential both and the interdependence of '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test + \" \" + new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ee53b-ebf4-4ba3-9f03-cc5dec98703d",
   "metadata": {},
   "source": [
    "## Next Steps  <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b83db6-16ba-45f3-a32a-53cc1c027674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e771b15-f506-4ab9-a94e-2e7ef907fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepgreen)",
   "language": "python",
   "name": "deepgreen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
