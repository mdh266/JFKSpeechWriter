{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fdfc78-95f2-41ea-8933-6e1ccce6ca9a",
   "metadata": {},
   "source": [
    "## Creating An AI-Based JFK Speech Writer: Part 2\n",
    "-----------------------\n",
    "\n",
    "__[1. Introduction](#first-bullet)__\n",
    "\n",
    "__[2. Data Preparation](#second-bullet)__\n",
    "\n",
    "__[3. A Bidirectional GRU Model](#third-bullet)__\n",
    "\n",
    "__[4. Generating Text](#fourth-bullet)__\n",
    "\n",
    "__[5. Next Steps](#fifth-bullet)__\n",
    "\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "----\n",
    "\n",
    "In this blog post I follow up on the last [post](http://michael-harmon.com/blog/jfk1.html) and develop a model for text generation using [Recurrent Neural Networks](https://en.wikipedia.org/wiki/Recurrent_neural_network). I'll build a bi-directional [gated recurrent unit (GRU)](https://en.wikipedia.org/wiki/Gated_recurrent_unit) that is trained on speeches made by [President John F. Kennedy](https://en.wikipedia.org/wiki/John_F._Kennedy). Specifically, I'll go over a how to build a model that predicts the \"next word\" in a sentence based off a sequence of the words coming before it. This project was challenging for me due to the data preparation needs of this problem. The data preparation was more involved then other posts that I have done on natural language processing since it involves modeling a sequences of words instead of using a \"[bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model).\"\n",
    "\n",
    "The concept of sequence modeling in recurrent neural networks is different from other models that I have done in the past and I will spend some time covering this topic. Interestingly, the next word prediction turns out to be a multi-class classification problem, albeit with a very large number of classes! Let's dig into the problem. \n",
    "\n",
    "The first step is to import the necessary [TensorFlow](https://www.tensorflow.org/) and [Google Cloud](https://www.tensorflow.org/) packages (since the data is in [Google Cloud Storage](https://cloud.google.com/storage?)) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9501bfaf-82da-4796-9d43-2faeb403eafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity('ERROR')\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b761f9-0cc8-4488-a4fe-de221841d6cb",
   "metadata": {},
   "source": [
    "## Data Preparation <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06a580-c28a-4bb6-bac3-a2d4691a6eb8",
   "metadata": {},
   "source": [
    "I can connect to [Google Cloud Storage](https://cloud.google.com/storage?) to download the all the concatenated speeches by President Kennedy. The first thing I do is get my credentials and then instantiate the client to connect to the bucket `gs://harmon-kennedy/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdc91d6-7a75-417b-8b59-87896ef101b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')\n",
    "client = storage.Client(project=credentials.project_id, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "44272e52-23c0-44dc-90c5-16b0f4d0cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = client.get_bucket(\"harmon-kennedy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda80a0a-175e-4220-b31d-c116dafb78f9",
   "metadata": {},
   "source": [
    "Then download all the speeches that were concatenated into one file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817b0d05-e64f-43b7-ae43-8f285d6d867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(\"all_jfk_speeches.txt\")\n",
    "text = blob.download_as_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27642d-1e15-400c-9940-b7e668bd1dce",
   "metadata": {},
   "source": [
    "I can see the first 300 characters of the text are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "481cf8e1-2fdd-49b3-8761-3732fbf62420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of particular importance to South Dakota are the farm policies of the Republican party - the party of Benson, Nixon and Mundt - the party which offers our young people no incentive to return to the farm - which offers the farmer only the prospect of lower and lower income - and which offers the nati'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c4565-e508-49ad-a47b-05bb9ed3339f",
   "metadata": {},
   "source": [
    "For getting situated I can get the number of characters in the text as well as the number of unique characters,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457436ac-a059-490b-972e-07865c7778ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 7734579 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687e8070-acc6-46aa-ac52-078205307ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f25ab2-61a1-442b-a3c7-c273290c7bc4",
   "metadata": {},
   "source": [
    "Since I'll be making a word level model this isn't totally helpful. Instead I'll get the total number of words and number of unique words. To do this I need to clean the text; convert newline characters to spaces, remove non-English characters and convert characters to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5eff3cd0-0b23-48bc-8104-50fe96dc19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.replace(\"\\n\", \" \").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "55f8db83-9920-467d-bbab-dce5cddce87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = [word.lower()for word in words if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f2720385-5146-412d-b740-4bdba2bcdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb4259-a678-4a40-a31d-72ea4378122b",
   "metadata": {},
   "source": [
    "The impact this had on the same text from above can be seen below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ebcbb8d3-4021-4e0e-837b-b1cbcaed9a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of particular importance to south dakota are the farm policies of the republican party the party of nixon and mundt the party which offers our young people no incentive to return to the farm which offers the farmer only the prospect of lower and lower income and which offers the nation the vision of'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c958cf-2857-44f2-85c5-1debb08cb07e",
   "metadata": {},
   "source": [
    "The total number of clean words and unique clean words in the text are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "31e792fb-2273-42f5-ba13-7e5aff02e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196835 number of clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(clean_words)} number of clean words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f84fb4b9-c4a0-4e15-b984-f23593f009dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19291 unique clean words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(set(clean_words))} unique clean words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac90d471-6f4c-4b92-9e63-c2c179dd06a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7533442"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f1925-d47e-4388-a83d-d5cadd1aa9da",
   "metadata": {},
   "source": [
    "The way a word level text generation model is built is to take a sequence of N words and then predict the next one. To create a training set, the text is split up into sliding widows where the feature vector **x** is the N words in the sequence of text and the target y is the N+1 word in that text. We repeat this N=1,2,3,4,... \n",
    "\n",
    "For instance take the sentence \"The man is walking down the street.\" To build a model that predicts the next word based on the 4 before it, its necessary to create the 4 training examples as shown below,\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/nextword.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://www.youtube.com/watch?v=VAMKuRAh2nc\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "For this model I will use `seq_length` to be the number words to use in the text to predict the next word. In order to be able to predict the next word I need to reduce the total number words that are possible to predict to a finite number. This means limiting the number of possible words to be of size `vocab_size` and in turn this classification problem will be a `vocab-size`-class problem.\n",
    "\n",
    "In order to convert the text which is represented as a sequence of words into numerical vectors I'll use the [TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) class. This technique is discussed in more in a prior post which you can read [here](http://michael-harmon.com/blog/NLP4.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c010404d-c093-49fa-a040-84eea850f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15000\n",
    "seq_length = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6f28d-d856-4ac8-995d-4097ad956b32",
   "metadata": {},
   "source": [
    "Now instantiate the TextVectorization layer and fit it to the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "dd525c78-50fb-4edf-a80d-1d9bb0cfe9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer_layer = TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    pad_to_max_tokens=True,\n",
    "    output_sequence_length=seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "74c5c2cb-31e0-492f-823d-5402f1e3c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 11:41:30.214279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "vectorizer_layer.adapt([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95d66a-9839-425f-9d6b-ece4d8ddbba9",
   "metadata": {},
   "source": [
    "I can then get the set of words in the vectorizer's \"vocabulary\" and create a dictionary to look up each word's equivalent numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b0adfe7c-c9b4-4997-9d81-53332c08d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15fcda3-3b45-4a21-b8f7-4985f2cfb5b0",
   "metadata": {},
   "source": [
    "The numerical value for each of the first two words in the example text above is then,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "97017125-2d21-4d13-ad8a-7ee54a9ed1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a9b20cd0-2586-448a-832d-0c50760769af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['particular']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288ab18-709b-4f59-9670-673bdd49f0af",
   "metadata": {},
   "source": [
    "The numerical value for the \"out of vocabulary\" token is,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b47c0035-4f44-48b4-8edb-7bc9b4f39114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['[UNK]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8192b-2747-4955-a65a-dadc41d71889",
   "metadata": {},
   "source": [
    "Next I'll create the dataset X and y, where X is the vector of features, which in turn are the sequence of words. The vector y is the target which is the next word in that sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "41f01a9d-5f4b-4388-a29e-468ddb8e5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_seq = [clean_words[i:i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]\n",
    "next_word = [clean_words[i + seq_length] for i in range(0, len(clean_words) - seq_length-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e414148-051d-43da-a694-3b14466d08e1",
   "metadata": {},
   "source": [
    "Each entry in `words_seq` is a list of the `seq_length` words or tokens that make that sequence in that training example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "241e7f43-c684-4977-a802-ac741f827a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['of', 'particular', 'importance', 'to', 'south', 'dakota', 'are',\n",
       "        'the', 'farm', 'policies'], dtype='<U20'),\n",
       " array(['particular', 'importance', 'to', 'south', 'dakota', 'are', 'the',\n",
       "        'farm', 'policies', 'of'], dtype='<U20')]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_seq[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f4cbe-27fb-4e33-b099-0f2bc8fa242a",
   "metadata": {},
   "source": [
    "I then convert those list of lists into a list of strings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ebfb75b6-e61d-4575-b3a8-eee2c5623dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['of particular importance to south dakota are the farm policies',\n",
       "       'particular importance to south dakota are the farm policies of'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\" \".join(words_seq[i]) for i in range(len(next_word)) if next_cat[i] != 1])\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd76360-491d-4d1b-9623-d6a56a263722",
   "metadata": {},
   "source": [
    "The reason for doing this is that this way my model will be able to take inputs that are just plain text instead of needing lists of strings that represent that text. The later would require that new inputs to the model be pre-processed before being feed into the trained model, while the latter means a trained model can just take raw text as the input.\n",
    "\n",
    "\n",
    "Notice that I only do this where the target word is not out of the vocabulary word. \n",
    "\n",
    "The next two words that correspond to the targets for the examples above are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1f6d20cc-c310-416f-b868-71f78366c31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'the']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a3a51-08e8-4ee9-bac1-b303b408db9c",
   "metadata": {},
   "source": [
    "Now I'll convert the target vector of \"next words\" to a vector with \"numerical values\" using the `word_index` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b121c151-2f0a-43c7-af72-4442aa2d4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_cat = np.array([word_index.get(word, 1) for word in next_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "817e9cb9-1b83-4b1a-87ee-c110d79d73b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cat[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bef3ba-cab0-457f-b585-6d2adeae3079",
   "metadata": {},
   "source": [
    "Lastly, I one-hot encode these numerical variables in the target vector and filter out those entries that correspond to the out of vocabulary tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0676294e-0c54-4686-ac32-5b08a4ca6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.keras.utils.to_categorical([cat for cat in next_cat if cat != 1])\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239a666-35f7-4faa-9e33-130392cdc905",
   "metadata": {},
   "source": [
    "The reason for filtering the out-of-vocabulary tokens is I don't want to train a model that predicts out-of-vocabulary words since this would be meaningless to end users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292b1a7-3150-4d37-b2b7-e06c3ae5b77b",
   "metadata": {},
   "source": [
    "The size of each of the datasets are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c5d66dd7-4830-4e8a-9581-c8c4b6b304d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179990,)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f5fedb18-88b8-48bc-a1b3-2b0ef538a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190502, 14999)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c264a6-105d-4eff-8b1f-749c3be1bf1d",
   "metadata": {},
   "source": [
    "Now to see what effect the vectorizer layer has on the text I'll feed the first two sequences above through the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "abcb148f-7bd2-47dd-a30c-cd668f96e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=int64, numpy=\n",
       "array([[   3,  758,  692,    5,  430, 2268,   16,    2,  156,  280],\n",
       "       [ 758,  692,    5,  430, 2268,   16,    2,  156,  280,    3]])>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_layer.call(X[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d4ce1-72c6-4d84-a9e3-73e592336708",
   "metadata": {},
   "source": [
    "The vectorizer layer converts the array of strings with shape `(1179990,)` to an matrix of integers of shape `(1179990, seq_length)`. Each entry in the array will be a integer from 1 to `vocab_size` and is the integer representation for each word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d42b72-0d91-4c25-83b3-c80362f00106",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A Bidirectional GRU Model  <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "------------\n",
    "[Recurrent Neural Networks (RNN)](https://en.wikipedia.org/wiki/Recurrent_neural_network) are used to model sequences. They use an internal state, **h**, to act as memory that processes these sequences and \"remember\" things from the past. A quintessential diagram of a RNN is shown below, \n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/rnn.svg\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://en.wikipedia.org/wiki/Recurrent_neural_network#/media/File:Recurrent_neural_network_unfold.svg/\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "An RNN cell is shown on the left and on the right is the \"un-rolled\" version that shows how the cell processes a sequence of inputs **x** into outputs **o**; there is a subscript *t* that denotes entry in the sequence. The subscript for each **h** is used to denote the value the internal state or memory cell in the t-th entry in the sequence.\n",
    "\n",
    "There are quite a few types of RNN's that are shown below,\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/types.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recurrent-neural-network/recurrent_neural_networks/\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "The model I am building in this post that uses a sequence of words to predict the next word is a \"many-to-one\" model. Zooming into the RNN cell we focus on a specific type of RNN called a [Gated Recurrent Unit (GRU)](https://en.wikipedia.org/wiki/Gated_recurrent_unit). The details of a GRU cell are shown below.\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/gru.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24198e23-b7a4-42aa-ae48-465f5e928b17",
   "metadata": {
    "tags": []
   },
   "source": [
    "There is a hidden state **h** that takes on values for each iteration *t*. There is a candidate update to the hidden state **h** with a ~ over it. The candidate update to the hidden state has values between -1 and +1 and is a function of the relevance gate **r** as well as the prior value of the hidden state and the current value of the input. The relevance gate is value between 0 and 1 and is a function of the prior value of the hidden state and the current value of the input. It controls the amount off effect that the prior hidden state value has on the candidate update value for the hidden state. \n",
    "\n",
    "Lastly there is a forget gate **z** which is between 0 and 1 is a function of the prior value of the hidden state and the current value of the input. The forget gate is used to control whether we update the hidden state value or not. If `z = 1` then we update the internal state to be the candidate state. If `z = 0`, the value for the hidden state remains unchanged.\n",
    "\n",
    "Notice the hidden state value **h** of one iteration can be fed directly into the RNN as well as the input **x**. These variables are not necessarily scalars and can be vectors. In the model I am building the variables will be vectors of dimension `seq_length`. The output of the RNN cell is a vector of size `vocab_size`. To convert the hidden state vector **x** to **y** we apply a softmax function.\n",
    "\n",
    "Many times in natural language processing models make use of a [bi-directional RNN](https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks). In this type of model two RNN cells are used, one processing the sequence in the forward direction and one processing the sequence in the reverse direction. The architecture is shown below:\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/bidirectionalgru.png\" alt=\"Trulli\" style=\"width:75%\">\n",
    "<figcaption align = \"center\">\n",
    "From https://www.researchgate.net/figure/The-structure-of-a-bidirectional-GRU-model_fig4_366204325\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba8d86-0b58-4ed1-b684-189bc6a3591c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice that the GRU cells at the same time *t* are both a function of the same input value **x**, but are functions of different iterations hidden states **h**. Both cells at the same iteration are used to compute the output at the same iteration. Bidirectional RNN's were introduced to increase the amount of input information available to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376515d-f487-4e99-b603-f1b6c010d086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb1277db-8120-4a6d-9aab-f7225341fe3f",
   "metadata": {},
   "source": [
    "I implement a bi-directional GRU model using [TensorFlow's subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models) methods below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6a3841fb-f5f8-41e1-a53f-2372d912dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9c871925-8d6d-4989-abfb-66ad1b1d50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    vectorizer_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(34)),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "864f0fc1-7975-4aeb-b766-8019b0111f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_7 (TextV  (None, 10)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 10, 128)           1920000   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 68)               33456     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 15000)             1035000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,988,456\n",
      "Trainable params: 2,988,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8f7b61a-8021-400a-a988-9158e897b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class JFKSpeechWriter(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 text: str, \n",
    "                 seq_length: int,\n",
    "                 vocab_size: int, \n",
    "                 embedding_dim: int, \n",
    "                 units: int) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vectorizer_layer = TextVectorization(\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    max_tokens=vocab_size,\n",
    "                                    output_mode=\"int\",\n",
    "                                    pad_to_max_tokens=True,\n",
    "                                    output_sequence_length=seq_length,\n",
    "                              )\n",
    "        self.embedding_layer =  tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.GRU_layer = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units))\n",
    "        self.dense_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "        \n",
    "        self.vectorizer_layer.adapt([text])\n",
    "        \n",
    "    def call(self, input_str: str) -> int:\n",
    "        # x = self.input_layer(input_str)\n",
    "        x = self.vectorizer_layer(input_str)\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.GRU_layer(x)\n",
    "        return self.dense_layer(x)\n",
    "        \n",
    "    def get_wordmap(self) -> Dict[int, str]:\n",
    "        voc = self.vectorizer_layer.get_vocabulary()\n",
    "        word_index = dict(zip(voc, range(len(voc))))\n",
    "        return dict(map(reversed, word_index.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d31d03-5ce9-4d8b-8d7d-6627bc284492",
   "metadata": {},
   "source": [
    "The subclassing method in TensorFlow is used for novel techniques mainly for research problems. The model I am building is pretty standard, but I wanted to use this opportunity play around with the subclassing methodology.\n",
    "\n",
    "In the constructor each layer of the model is declared as an attribute of the object and the vectorizer layer is instantiated. The `call` method of the class is used to define the forward form of the model. Like in all Keras models, the forward form is all that is needed to be defined and Keras/Tensorflow handles computing the necessary information needed for [backpropegation](https://en.wikipedia.org/wiki/Backpropagation). The model consists of a vectorizer layer which converts the text which is made up of `seq_length` words into a `seq_length`-dimensional vector of integers that taken values between 1 and `vocab_size`. Next an embedding layer is applied, followed by a bi-directional GRU layer and softmax as the last layer to predict which of the `vocab_size` class the next word is.\n",
    "\n",
    "The last method of the class is `get_wordmap`. This function returns the reverse dictionary that converts a integer representation of words back to its English version. This function is used for converting the output of the model back an English word.\n",
    "\n",
    "Now, the model can be instantiated with 128 dimensional embedding layer and 64 unit GRU layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e437ea74-66aa-4443-b9ba-0546c723d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:00:10.472779: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = JFKSpeechWriter(text=text, \n",
    "                        seq_length=10, \n",
    "                        vocab_size=15000, \n",
    "                        embedding_dim=128, \n",
    "                        units=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12460e-0627-4989-85c4-2093013e4c52",
   "metadata": {},
   "source": [
    "Notice that for the vectorizer layer I have to pass the original text, `seq_length` and the `vocab_size` values to initialize that layer properly. \n",
    "\n",
    "Now we can compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "90115353-02c6-4a9b-ba91-5d3f58ee31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdc123-9532-4574-8ee0-b50664711ffa",
   "metadata": {},
   "source": [
    "Normally in a Tensorflow model using a [Sequential model](https://www.tensorflow.org/guide/keras/sequential_model) or the [Functional API](https://www.tensorflow.org/guide/keras/functional) once the model is compiled the [summary](https://keras.io/api/models/model/#summary-method) method can be used to return information on the model. However, compiling the model is not sufficient for using the [summary](https://keras.io/api/models/model/#summary-method) method in the subclassing API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63d17714-af04-444e-8eb7-9093ceae9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f976cdd-2a28-487d-9590-908aee6cfd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:100000], y[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "109c3692-dfcc-4477-8049-99a421ae1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd91066d-360d-4965-b820-0ffb377b57a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'state laws in states such as massachusetts on the other hand union security provisions more liberal than tafthartley are not'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f0d5852d-b459-4076-8da3-972b6e4bc76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:00:17.790011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.016253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.025332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.136763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:18.151356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/625 [============================>.] - ETA: 0s - loss: 6.7281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:00:38.088691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:38.185708: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 18:00:38.195500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 24s 36ms/step - loss: 6.7286 - val_loss: 6.4995\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 6.3093 - val_loss: 6.4152\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 6.1363 - val_loss: 6.3013\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 20s 33ms/step - loss: 5.9251 - val_loss: 6.2154\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 5.7108 - val_loss: 6.1584\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 5.5084 - val_loss: 6.1019\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 5.3100 - val_loss: 6.0729\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 5.1067 - val_loss: 6.0613\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 4.9310 - val_loss: 6.0495\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 4.7657 - val_loss: 6.0480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dbdfd430>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f48f1138-1d0e-464c-af38-91abe75cbb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 07:42:02.923068: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x2dbebc400> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x2e4f8e8b0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"jfk_model\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e56b263f-563d-453b-8442-bc19585a0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"jfk_speech_writer_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_4 (TextV  multiple                 0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     multiple                  1280000   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  multiple                 74496     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  1290000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,644,496\n",
      "Trainable params: 2,644,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1185a6-16e6-4110-892f-768c77c0296e",
   "metadata": {},
   "source": [
    "## Generating Text  <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1c674c83-7731-470a-b6d3-ef5eebc76154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 07:42:58.035546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-07 07:42:58.040803: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"jfk_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "185f96ca-5f2b-4580-bc14-194cb2963bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = str(X[688394])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "626a08ad-a625-4c14-b148-ab071a2e6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and constitution and in the american public school system and he stated flatly that he recognized no power in the'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9385fdf7-eeb3-462c-ac0b-a6210ddb3b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:59:49.825963: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 17:59:49.895592: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-06 17:59:49.905844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4ca25393-54b9-46e6-832c-9a19a68d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = model.get_wordmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649441b5-ee54-47f7-bd60-19dcad6a3674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e4045a40-ed4a-43e9-bc4c-99e99bd4f687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'united'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map[np.argmax(y_pred[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceef283-b331-46c3-9ff3-0d8bec8b178f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "966ff16b-4dc2-465c-947a-5a7e0220b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_words(input_str, n):\n",
    "    final_str = ''\n",
    "    for i in range(n):\n",
    "        prediction = model.predict([input_str], verbose=0)\n",
    "        next_word = reverse_word_map[np.argmax(prediction[0])]\n",
    "        final_str += next_word + ' ' \n",
    "        input_str += ' ' + next_word\n",
    "        input_str = ' '.join(input_str.split(' ')[1:])\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d16adbda-a19d-4077-b874-f9bd3a882b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = next_words(test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ddebd14f-9b7a-47af-bc03-accd70231cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and constitution and in the american public school system and he stated flatly that he recognized no power in the words of the house of representatives and women of the '"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test + \" \" + new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ee53b-ebf4-4ba3-9f03-cc5dec98703d",
   "metadata": {},
   "source": [
    "## Next Steps  <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b83db6-16ba-45f3-a32a-53cc1c027674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e771b15-f506-4ab9-a94e-2e7ef907fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepgreen)",
   "language": "python",
   "name": "deepgreen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
